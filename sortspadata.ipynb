{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from st_dbscan import ST_DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract number from ID\n",
    "def extract_number_from_id(id_string):\n",
    "    return int(id_string.split('_')[-1])\n",
    "\n",
    "# Directory containing CSV files\n",
    "directory = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\event_time_list\"\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Loop through each row\n",
    "        for index, row in df.iterrows():\n",
    "            # Extract number from ID in column 0\n",
    "            number = extract_number_from_id(row['FOV_cell_label'])\n",
    "            \n",
    "            # Assign the extracted number to 'Cell_number' column\n",
    "            df.at[index, 'Cell_number'] = number\n",
    "        \n",
    "        # Save the modified DataFrame back to the file\n",
    "        df.to_csv(filepath, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique rows based on specified columns: 2489\n",
      "Unique rows saved to: C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\unique_coordinates.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "file_path_spatial = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\20220423_original_and_review_all_events_df.csv\"\n",
    "df = pd.read_csv(file_path_spatial)\n",
    "\n",
    "# Specify the columns to consider for uniqueness\n",
    "unique_columns = [9, 12, 13]  # Assuming column indices are 0-indexed\n",
    "\n",
    "# Select only the specified columns\n",
    "selected_columns = df.iloc[:, unique_columns]\n",
    "\n",
    "# Get the count of unique rows\n",
    "unique_rows_count = selected_columns.drop_duplicates().shape[0]\n",
    "\n",
    "print(\"Number of unique rows based on specified columns:\", unique_rows_count)\n",
    "# Load the CSV file\n",
    "file_path = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\coordinates.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop duplicates based on columns 0, 3, and 4\n",
    "unique_df = df.drop_duplicates(subset=[df.columns[0], df.columns[3], df.columns[4]])\n",
    "\n",
    "# Define the path for the new file\n",
    "new_file_path = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\unique_coordinates.csv\"\n",
    "\n",
    "# Save the unique dataframe into a new CSV file\n",
    "unique_df.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(f\"Unique rows saved to: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique rows saved to: C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\unique_coordinates.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the original file\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\coordinates.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop duplicates based on 'Cell_Number', 'Slip_Area', and 'expt' columns\n",
    "unique_df = df.drop_duplicates(subset=['Cell_Number', 'Slip_Area', 'expt'])\n",
    "\n",
    "# Define the path for the new file\n",
    "new_file_path = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\unique_coordinates.csv\"\n",
    "\n",
    "# Save the unique dataframe into a new CSV file\n",
    "unique_df.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(f\"Unique rows saved to: {new_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for 'L231' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\L231_data.csv'\n",
      "Saved data for 'LHs578t' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\LHs578t_data.csv'\n",
      "Saved data for 'LSUM159' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\LSUM159_data.csv'\n",
      "Saved data for 'LCal51' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\LCal51_data.csv'\n",
      "Saved data for 'SUM159' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\SUM159_data.csv'\n",
      "Saved data for 'Cal51' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\Cal51_data.csv'\n",
      "Saved data for 'LBT474' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\LBT474_data.csv'\n",
      "Saved data for 'LT47D' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\LT47D_data.csv'\n",
      "Saved data for 'L468' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\L468_data.csv'\n",
      "Saved data for 'L453' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\L453_data.csv'\n",
      "Saved data for 'BT474' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\BT474_data.csv'\n",
      "Saved data for 'standard' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\standard_data.csv'\n",
      "Saved data for 'TTX_10um' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\TTX_10um_data.csv'\n",
      "Saved data for 'TTX_10um_washout' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\TTX_10um_washout_data.csv'\n",
      "Saved data for 'TTX_1um' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\TTX_1um_data.csv'\n",
      "Saved data for 'MCF10A' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\MCF10A_data.csv'\n",
      "Saved data for 'MCF10A_TGFB' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\MCF10A_TGFB_data.csv'\n",
      "Saved data for 'LMCF10A_TGFB_0314' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\LMCF10A_TGFB_0314_data.csv'\n",
      "Saved data for 'LMCF10A_TGFB_0304' to 'C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\\LMCF10A_TGFB_0304_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save each cell type into a new file \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\unique_coordinates.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the folder path to save files\n",
    "folder_path = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\"\n",
    "\n",
    "# Get unique values in the 'expt' column\n",
    "unique_expts = df['expt'].unique()\n",
    "\n",
    "# Iterate over unique expt values\n",
    "for expt_value in unique_expts:\n",
    "    # Filter dataframe for rows with the current expt value\n",
    "    expt_df = df[df['expt'] == expt_value]\n",
    "    \n",
    "    # Define the filename based on expt value\n",
    "    filename = os.path.join(folder_path, f\"{expt_value}_data.csv\")\n",
    "    \n",
    "    # Save filtered dataframe to file\n",
    "    expt_df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Saved data for '{expt_value}' to '{filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No corresponding file found for 'L231_data.csv'\n",
      "No corresponding file found for 'L453_data.csv'\n",
      "No corresponding file found for 'L468_data.csv'\n",
      "Merged files 'LBT474_data.csv' and 'BT474_data.csv', saved as 'LBT474_data.csv'\n",
      "Deleted 9 rows in 'LBT474_data.csv'\n",
      "Merged files 'LCal51_data.csv' and 'Cal51_data.csv', saved as 'LCal51_data.csv'\n",
      "Deleted 0 rows in 'LCal51_data.csv'\n",
      "No corresponding file found for 'LHs578t_data.csv'\n",
      "No corresponding file found for 'LMCF10A_TGFB_0304_data.csv'\n",
      "No corresponding file found for 'LMCF10A_TGFB_0314_data.csv'\n",
      "Merged files 'LSUM159_data.csv' and 'SUM159_data.csv', saved as 'LSUM159_data.csv'\n",
      "Deleted 0 rows in 'LSUM159_data.csv'\n",
      "No corresponding file found for 'LT47D_data.csv'\n",
      "Total files deleted: 3\n",
      "Total rows deleted: 9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\"\n",
    "\n",
    "# Initialize counter for deleted files and rows\n",
    "deleted_files_count = 0\n",
    "total_deleted_rows = 0\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the filename has an 'L' prefix\n",
    "    if filename.startswith('L'):\n",
    "        # Construct the corresponding filename without 'L'\n",
    "        corresponding_filename = filename[1:]\n",
    "        \n",
    "        # Check if the corresponding file exists\n",
    "        if corresponding_filename in os.listdir(folder_path):\n",
    "            # Load both files\n",
    "            df_with_l = pd.read_csv(os.path.join(folder_path, filename))\n",
    "            df_without_l = pd.read_csv(os.path.join(folder_path, corresponding_filename))\n",
    "            \n",
    "            # Merge the two dataframes\n",
    "            merged_df = pd.concat([df_with_l, df_without_l])\n",
    "            \n",
    "            # Count the number of rows before removing duplicates\n",
    "            total_rows_before = merged_df.shape[0]\n",
    "            \n",
    "            # Remove duplicate rows based on columns 3 and 4\n",
    "            merged_df.drop_duplicates(subset=[merged_df.columns[3], merged_df.columns[4]], inplace=True)\n",
    "            \n",
    "            # Count the number of rows after removing duplicates\n",
    "            total_rows_after = merged_df.shape[0]\n",
    "            \n",
    "            # Calculate the number of rows deleted in this file\n",
    "            rows_deleted_in_file = total_rows_before - total_rows_after\n",
    "            \n",
    "            # Save the merged dataframe with the filename that has 'L' prefix\n",
    "            merged_filename = os.path.join(folder_path, filename)\n",
    "            merged_df.to_csv(merged_filename, index=False)\n",
    "            \n",
    "            print(f\"Merged files '{filename}' and '{corresponding_filename}', saved as '{filename}'\")\n",
    "            print(f\"Deleted {rows_deleted_in_file} rows in '{filename}'\")\n",
    "            \n",
    "            # Remove the corresponding file without 'L' prefix\n",
    "            os.remove(os.path.join(folder_path, corresponding_filename))\n",
    "            \n",
    "            # Increment the counters for deleted files and rows\n",
    "            deleted_files_count += 1\n",
    "            total_deleted_rows += rows_deleted_in_file\n",
    "        else:\n",
    "            print(f\"No corresponding file found for '{filename}'\")\n",
    "\n",
    "print(f\"Total files deleted: {deleted_files_count}\")\n",
    "print(f\"Total rows deleted: {total_deleted_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed file '231_data.csv' to '231.csv'\n",
      "Renamed file '453_data.csv' to '453.csv'\n",
      "Renamed file '468_data.csv' to '468.csv'\n",
      "Renamed file 'BT474_data.csv' to 'BT474.csv'\n",
      "Renamed file 'Cal51_data.csv' to 'Cal51.csv'\n",
      "Renamed file 'Hs578t_data.csv' to 'Hs578t.csv'\n",
      "Renamed file 'MCF10A_data.csv' to 'MCF10A.csv'\n",
      "Renamed file 'MCF10A_TGFB_0304_data.csv' to 'MCF10A_TGFB_0304.csv'\n",
      "Renamed file 'MCF10A_TGFB_0314_data.csv' to 'MCF10A_TGFB_0314.csv'\n",
      "Renamed file 'MCF10A_TGFB_data.csv' to 'MCF10A_TGFB.csv'\n",
      "Renamed file 'standard_data.csv' to 'standard.csv'\n",
      "Renamed file 'SUM159_data.csv' to 'SUM159.csv'\n",
      "Renamed file 'T47D_data.csv' to 'T47D.csv'\n",
      "Renamed file 'TTX_10um_data.csv' to 'TTX_10um.csv'\n",
      "Renamed file 'TTX_10um_washout_data.csv' to 'TTX_10um_washout.csv'\n",
      "Renamed file 'TTX_1um_data.csv' to 'TTX_1um.csv'\n",
      "Total files renamed: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\"\n",
    "\n",
    "# Initialize counter for renamed files\n",
    "renamed_files_count = 0\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Remove the '_data' suffix\n",
    "    if filename.endswith('_data.csv'):\n",
    "        new_filename = filename[:-9] + \".csv\"  # Remove '_data.csv' and append '.csv'\n",
    "        \n",
    "        # Rename the file\n",
    "        os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_filename))\n",
    "        \n",
    "        print(f\"Renamed file '{filename}' to '{new_filename}'\")\n",
    "        renamed_files_count += 1\n",
    "\n",
    "print(f\"Total files renamed: {renamed_files_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed file '468.csv' to '468_index.csv'\n",
      "Renamed file 'BT474.csv' to 'BT474_index.csv'\n",
      "Renamed file 'Cal51.csv' to 'Cal51_index.csv'\n",
      "Renamed file 'Hs578t.csv' to 'Hs578t_index.csv'\n",
      "Renamed file 'MCF10A.csv' to 'MCF10A_index.csv'\n",
      "Renamed file 'MCF10A_TGFB.csv' to 'MCF10A_TGFB_index.csv'\n",
      "Renamed file 'MCF10A_TGFB_0304.csv' to 'MCF10A_TGFB_0304_index.csv'\n",
      "Renamed file 'MCF10A_TGFB_0314.csv' to 'MCF10A_TGFB_0314_index.csv'\n",
      "Renamed file 'standard.csv' to 'standard_index.csv'\n",
      "Renamed file 'SUM159.csv' to 'SUM159_index.csv'\n",
      "Renamed file 'T47D.csv' to 'T47D_index.csv'\n",
      "Renamed file 'TTX_10um.csv' to 'TTX_10um_index.csv'\n",
      "Renamed file 'TTX_10um_washout.csv' to 'TTX_10um_washout_index.csv'\n",
      "Renamed file 'TTX_1um.csv' to 'TTX_1um_index.csv'\n",
      "Total files renamed: 14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"C:\\Users\\ainii\\OneDrive\\Documents\\TempSpa\\locations\\sortedfiles\\ST-DBSCAN\\temp_spatial_coordinates_data\"\n",
    "\n",
    "# Initialize counter for renamed files\n",
    "renamed_files_count = 0\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is a CSV file\n",
    "    if filename.endswith('.csv'):\n",
    "        # Add the '_index' suffix before the file extension\n",
    "        new_filename = filename.replace('.csv', '_index.csv')\n",
    "        \n",
    "        # Rename the file\n",
    "        os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_filename))\n",
    "        \n",
    "        print(f\"Renamed file '{filename}' to '{new_filename}'\")\n",
    "        renamed_files_count += 1\n",
    "\n",
    "print(f\"Total files renamed: {renamed_files_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
